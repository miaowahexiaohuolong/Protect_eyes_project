import streamlit as st
import os
import json
import time
import gc
import contextlib
import io
import re
import ast

# MLX ç›¸å…³
from mlx_lm import load

# ================= å¼•å…¥è‡ªå®šä¹‰æ¨¡å— =================
try:
    from step2_build import build_knowledge_base
    from agent_flow_extra_keyword_and_search import HealthAgent
    from step3_rag import LightRAGBot
except ImportError as e:
    st.error(f"âŒ ç¼ºå°‘å¿…è¦æ–‡ä»¶: {e}")
    st.stop()

# ================= é¡µé¢é…ç½® & CSS ç¾åŒ– =================
st.set_page_config(
    page_title="Evidence-based Health Claims Checker",
    page_icon="ğŸ©º",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ³¨å…¥ CSSï¼šè§£å†³å­—ä½“ä¸ç»Ÿä¸€ï¼Œå¢åŠ åˆ—è¡¨æ ·å¼
st.markdown("""
    <style>
    /* Global font */
    html, body, [class*="css"] {
        font-family: -apple-system, "Microsoft YaHei", "Segoe UI", Roboto, sans-serif !important;
        color: #333;
    }
    /* Card */
    .report-card {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 25px;
        margin-bottom: 20px;
        box-shadow: 0 2px 5px rgba(0,0,0,0.05);
    }
    /* Section header */
    .section-header {
        font-size: 20px;
        font-weight: 700;
        color: #2c3e50;
        margin-bottom: 15px;
        border-bottom: 2px solid #f0f0f0;
        padding-bottom: 8px;
    }
    /* List */
    ul.custom-list {
        margin-top: 5px;
        padding-left: 20px;
    }
    ul.custom-list li {
        margin-bottom: 8px;
        line-height: 1.6;
        font-size: 16px;
    }
    /* Final conclusion box */
    .conclusion-box {
        background-color: #e8f4fd;
        border: 1px solid #b6e0fe;
        border-left: 6px solid #2196f3;
        border-radius: 8px;
        padding: 20px;
        font-size: 17px;
        font-weight: 500;
        color: #0d47a1;
        margin-top: 10px;
    }
    </style>
""", unsafe_allow_html=True)

# ================= æ ¸å¿ƒé…ç½® =================
class Config:
    MODEL_NAME = "mlx-community/Qwen2.5-7B-Instruct-4bit"
    # âœ… ä¿ç•™æ‚¨çš„ Adapter (å› ä¸ºæ‚¨éœ€è¦å®ƒæ¥æå–å…³é”®è¯)
    ADAPTER_DIR = "deepseek_clear_Data/my_adapters_7b" 
    #ADAPTER_DIR = None
    
    os.environ["HF_ENDPOINT"] = "https://hf-mirror.com" 
    KB_DIR = "my_knowledge_base"
    INDEX_FILE = os.path.join(KB_DIR, "health.index")
    META_FILE = os.path.join(KB_DIR, "health.pkl")

# ================= èµ„æºç®¡ç† =================
def clean_memory():
    gc.collect()
    try:
        import mlx.core as mx
        if hasattr(mx, "clear_cache"): mx.clear_cache()
        elif hasattr(mx, "metal"): mx.metal.clear_cache()
    except: pass

@st.cache_resource(show_spinner=False)
def load_engine():
    print("ğŸš€ [System] æ­£åœ¨åˆå§‹åŒ– AI æ¨¡å‹...")
    model, tokenizer = load(Config.MODEL_NAME, adapter_path=Config.ADAPTER_DIR)
    print("âœ… AI æ¨¡å‹åŠ è½½å®Œæ¯•ï¼")
    return model, tokenizer

# ================= æ ¸å¿ƒä¿®å¤ï¼šè¶…çº§è§£æå™¨ =================

def format_content_as_list(content):
    """
    å°†å†…å®¹å¼ºåˆ¶è½¬æ¢ä¸º HTML åˆ—è¡¨æ ¼å¼ (è§£å†³ä¸åˆ†ç‚¹çš„é—®é¢˜)
    """
    if not content:
        return "æš‚æ— è¯¦ç»†å†…å®¹"
    
    html = '<ul class="custom-list">'
    
    # å¦‚æœå·²ç»æ˜¯åˆ—è¡¨ï¼Œç›´æ¥éå†
    if isinstance(content, list):
        for item in content:
            item_str = str(item).replace('"', '').strip()
            if item_str:
                html += f"<li>{item_str}</li>"
    
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•æŒ‰å¸¸è§åˆ†éš”ç¬¦åˆ‡åˆ†
    elif isinstance(content, str):
        # å»æ‰ JSON ç¬¦å·
        clean_str = content.replace("[", "").replace("]", "").replace('"', "").replace("'", "")
        # æŒ‰é€—å·æˆ–åˆ†å·åˆ‡åˆ†
        items = re.split(r'[;ï¼›,ï¼Œ]', clean_str)
        for item in items:
            if item.strip():
                html += f"<li>{item.strip()}</li>"
    
    html += '</ul>'
    return html

def extract_all_json(text):
    """
    å…¨æ–‡æ‰«æï¼Œæå–æ‰€æœ‰å¯èƒ½çš„ JSON å¯¹è±¡ (è§£å†³æ¼æ‰æœ€ç»ˆç»“è®ºçš„é—®é¢˜)
    """
    merged_data = {}
    
    # 1. ä½¿ç”¨ finditer æŸ¥æ‰¾æ‰€æœ‰ {...} å—ï¼Œè€Œä¸ä»…ä»…æ˜¯ç¬¬ä¸€ä¸ª
    # è¿™ä¸€æ­¥éå¸¸å…³é”®ï¼Œå› ä¸ºæ‚¨çš„æ¨¡å‹è¾“å‡ºå¾€å¾€æ˜¯æ•£è½åœ¨å„å¤„çš„ JSON
    matches = re.finditer(r'(\{.*?\})', text, re.DOTALL)
    
    for match in matches:
        json_str = match.group(1).replace("\n", " ")
        try:
            # å°è¯•è§£æ
            data = json.loads(json_str)
        except:
            try:
                data = ast.literal_eval(json_str)
            except:
                continue # è§£æå¤±è´¥è·³è¿‡
        
        if isinstance(data, dict):
            merged_data.update(data) # åˆå¹¶æ‰€æœ‰æ‰¾åˆ°çš„æ•°æ®
            
    return merged_data

def display_polished_report(raw_text):
    """
    UI render (English)
    """
    data = extract_all_json(raw_text)
    verdict = "Analysis completed"
    literature_html = ""
    final_conclusion = "Please refer to the detailed analysis above."

    # --- Verdict ---
    found_verdict = False
    for k in ["verdict", "conclusion", "æ ¸å¿ƒç»“è®º", "æœ€ç»ˆç»“è®º"]:
        if k in data:
            verdict = str(data[k]).replace('"', '').replace("'", "")
            found_verdict = True
            break
    if not found_verdict:
        v_match = re.search(r'(ğŸ”´|ğŸŸ¡|ğŸŸ¢|âšªï¸)\s*([^\n]+)', raw_text)
        if v_match:
            verdict = v_match.group(0)

    # --- Literature sections ---
    field_map = {
        "claims": "ğŸ—£ Claims & Ingredients",
        "pros": "âœ… Product Pros / Supporting Evidence",
        "evidence": "ğŸ“š Scientific Evidence / Literature Conclusions",
        "contradictions": "âš ï¸ Contradictions / Risk Notes",
        "studies": "ğŸ“– Related Studies",
        "ingredients": "ğŸ§ª Key Ingredients"
    }
    lit_sections = []
    for key, title in field_map.items():
        if key in data and data[key]:
            content_list = format_content_as_list(data[key])
            if "<li>" in content_list:
                section_html = f"<div><strong>{title}</strong></div>{content_list}"
                lit_sections.append(section_html)
    if lit_sections:
        literature_html = "<br>".join(lit_sections)
    else:
        clean_raw = raw_text.replace("{", "").replace("}", "").replace('"', "")
        literature_html = f"<p>{clean_raw}</p>"

    # --- Final conclusion ---
    for k in ["recommendation", "advice", "suggestion", "expert_advice", "æœ€ç»ˆç»“è®º", "final_conclusion"]:
        if k in data and data[k]:
            final_conclusion = str(data[k])
            if isinstance(data[k], list):
                final_conclusion = "ï¼›".join([str(x) for x in data[k]])
            break

    # ================= Render =================
    st.markdown("### ğŸ“ Expert Verification Report")
    st.markdown("---")

    check_str = str(verdict) + str(raw_text)
    if any(x in check_str for x in ["è™šå‡", "å‡", "Fake", "False", "ğŸ”´"]):
        st.error(f"ğŸ”´ Core Verdict: {verdict.replace('ğŸ”´', '')}")
    elif any(x in check_str for x in ["å¤¸å¤§", "ä¸å®", "ğŸŸ¡", "Exaggerated", "Unsubstantiated"]):
        st.warning(f"ğŸŸ¡ Core Verdict: {verdict.replace('ğŸŸ¡', '')}")
    elif any(x in check_str for x in ["æœ‰æ•ˆ", "çœŸå®", "ğŸŸ¢", "Valid", "True"]):
        st.success(f"ğŸŸ¢ Core Verdict: {verdict.replace('ğŸŸ¢', '')}")
    else:
        st.info(f"ğŸ”µ Core Verdict: {verdict}")

    if "<li>" in literature_html or len(lit_sections) > 0:
        st.markdown('<div class="report-card">', unsafe_allow_html=True)
        st.markdown('<div class="section-header">2. Literature Analysis</div>', unsafe_allow_html=True)
        st.markdown(literature_html, unsafe_allow_html=True)
        st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="report-card">', unsafe_allow_html=True)
    st.markdown('<div class="section-header">3. Final Recommendation</div>', unsafe_allow_html=True)
    st.markdown(f'<div class="conclusion-box">{final_conclusion}</div>', unsafe_allow_html=True)
    st.markdown('</div>', unsafe_allow_html=True)


# ================= Web App ä¸»é€»è¾‘ =================
def main():
    with st.sidebar:
        st.title("ğŸ©º Evidence-based Health Claims Checker")
        st.markdown("---")
        
        with st.status("System Status", expanded=True):
            try:
                model, tokenizer = load_engine()
                st.write("âœ… Model loaded")
                st.write(f"ğŸ”§ Adapter: {os.path.basename(Config.ADAPTER_DIR)}")
            except Exception as e:
                st.error(f"Failed to load: {e}")
                st.stop()
        
        if st.button("ğŸ§¹ Clear VRAM"):
            clean_memory()
            st.toast("VRAM cleared")

    st.header("ğŸ” Fact-check health products/claims")
    
    col1, col2 = st.columns([4, 1])
    with col1:
        user_input = st.text_area("Enter ad content", height=100, placeholder="e.g., Taking lutein can completely cure myopia...", label_visibility="collapsed")
    with col2:
        st.markdown("<br>", unsafe_allow_html=True)
        start_btn = st.button("Start Verification â¤", type="primary", use_container_width=True)

    if start_btn and user_input:
        log_buffer = io.StringIO()
        log_placeholder = st.empty()
        
        with st.status("ğŸš€ Running full analysis...", expanded=True) as status:
            try:
                with contextlib.redirect_stdout(log_buffer):
                    
                    # Step 1
                    status.update(label="ğŸŒ [1/3] Extracting keywords & searching...", state="running")
                    print(f"ğŸ”¹ Target: {user_input}\n")
                    def update_log(): log_placeholder.code(log_buffer.getvalue(), language="bash")

                    agent = HealthAgent(model=model, tokenizer=tokenizer, filename="dataset.json")
                    agent.run(user_input)
                    update_log()
                    clean_memory()

                    # Step 2
                    status.update(label="ğŸ“š [2/3] Building knowledge base...", state="running")
                    build_knowledge_base()
                    update_log()

                    # Step 3
                    status.update(label="ğŸ§  [3/3] Generating final report...", state="running")
                    bot = LightRAGBot(model=model, tokenizer=tokenizer)
                    bot.verify(user_input)
                    update_log()

                status.update(label="âœ… Analysis completed", state="complete", expanded=False)
                
                full_log = log_buffer.getvalue()
                raw_report = full_log[-4000:] 
                if "-" * 60 in full_log:
                    parts = full_log.split("-" * 60)
                    if len(parts) >= 2: 
                        raw_report = parts[-2] + parts[-1]

                display_polished_report(raw_report)

            except Exception as e:
                status.update(label="âŒ Error occurred", state="error")
                st.error(str(e))
                import traceback
                st.code(traceback.format_exc())
            finally:
                log_buffer.close()
                clean_memory()

if __name__ == "__main__":
    main()