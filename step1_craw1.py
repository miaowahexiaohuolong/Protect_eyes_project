import json
import time
from pymed import PubMed

# ================= é…ç½® =================
TOOL_NAME = "HealthVerifierAgent"
EMAIL = "mc56508@um.edu.mo"  # ä½ çš„é‚®ç®±
OUTPUT_FILE = "raw_data.json" # çˆ¬å–ç»“æœä¿å­˜çš„æ–‡ä»¶å
MAX_RESULTS = 500              # ä¸ºäº†æµ‹è¯•ï¼Œæ¯ä¸ªè¯å…ˆçˆ¬ 10 ç¯‡
# =======================================

def crawl_pubmed(keywords):
    print(f"ğŸ•·ï¸ æ­£åœ¨åˆå§‹åŒ–çˆ¬è™« (Keywords: {keywords})...")
    pubmed = PubMed(tool=TOOL_NAME, email=EMAIL)
    
    all_articles = []
    
    for kw in keywords:
        print(f"   -> æ­£åœ¨æœç´¢å…³é”®è¯: '{kw}' ...")
        try:
            # æ‰§è¡ŒæŸ¥è¯¢
            results = pubmed.query(kw, max_results=MAX_RESULTS)
            
            count = 0
            for article in results:
                # æå–æˆ‘ä»¬éœ€è¦çš„ä¿¡æ¯
                article_id = article.pubmed_id.split()[0] if article.pubmed_id else str(time.time())
                title = article.title if article.title else "No Title"
                abstract = article.abstract if article.abstract else ""
                
                # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œè¿™ç¯‡æ–‡çŒ®å¯¹ RAG æ²¡ç”¨ï¼Œè·³è¿‡
                if not abstract: 
                    continue

                all_articles.append({
                    "id": article_id,
                    "title": title,
                    "abstract": abstract,
                    "url": f"https://pubmed.ncbi.nlm.nih.gov/{article_id}/"
                })
                count += 1
            print(f"      æˆåŠŸæŠ“å– {count} ç¯‡ã€‚")
            
        except Exception as e:
            print(f"      å‡ºé”™: {e}")
    
    return all_articles

def save_to_json(data):
    if not data:
        print("âŒ æ²¡æœ‰æ•°æ®è¢«ä¿å­˜ã€‚")
        return

    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=4)
    
    print(f"\nâœ… çˆ¬å–å®Œæˆï¼")
    print(f"ğŸ“¦ å…±æ”¶é›† {len(data)} ç¯‡æ–‡çŒ®ã€‚")
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜è‡³: {OUTPUT_FILE} (ä½ å¯ä»¥æ‰“å¼€è¿™ä¸ªæ–‡ä»¶æ£€æŸ¥å†…å®¹)")

if __name__ == "__main__":
    # è¿™é‡Œä½ å¯ä»¥æ‰‹åŠ¨è¾“å…¥æƒ³çˆ¬çš„è¯ï¼Œæˆ–è€…å†™æ­»åœ¨ä»£ç é‡Œ
    user_input = input("è¯·è¾“å…¥è¦çˆ¬å–çš„å…³é”®è¯ (ç”¨é€—å·åˆ†éš”ï¼Œä¾‹å¦‚ 'Myopia, Eye fatigue'): ")
    
    if not user_input.strip():
        keywords = ["Myopia control", "Blue light eye damage"] # é»˜è®¤æµ‹è¯•è¯
    else:
        keywords = [k.strip() for k in user_input.split(',')]
        
    data = crawl_pubmed(keywords)
    save_to_json(data)